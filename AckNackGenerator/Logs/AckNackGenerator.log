2020-06-16 15:31:53.934  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:31:53.944  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-16 15:31:54.180  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 224ms. Found 2 MongoDB repository interfaces.
2020-06-16 15:31:54.204  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:31:54.207  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-16 15:31:54.231  INFO 6584 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:31:54.232  INFO 6584 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:31:54.232  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 14ms. Found 0 Redis repository interfaces.
2020-06-16 15:31:54.956  INFO 6584 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-16 15:31:54.966  INFO 6584 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-16 15:31:54.966  INFO 6584 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-16 15:31:55.050  INFO 6584 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-16 15:31:55.050  INFO 6584 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2313 ms
2020-06-16 15:31:55.291  INFO 6584 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-16 15:31:55.387  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:31:55.422  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:31:55.423  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:31:56.576  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:27891}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.576  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:18878}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-16 15:31:56.576  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:18761}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-16 15:31:56.657  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77215000, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:31:50 IST 2020, lastUpdateTimeNanos=59126746175600}
2020-06-16 15:31:56.658  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77755600, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:31:50 IST 2020, lastUpdateTimeNanos=59126746175600}
2020-06-16 15:31:56.657  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77256900, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000008, setVersion=2, lastWriteDate=Tue Jun 16 15:31:50 IST 2020, lastUpdateTimeNanos=59126746175500}
2020-06-16 15:31:56.659  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000008 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.659  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.660  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.725  INFO 6584 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-16 15:31:57.560  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:58.956  INFO 6584 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-16 15:31:59.047  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.048  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.048  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719043
2020-06-16 15:31:59.053  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.056  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.090  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.099  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.100  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.100  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719099
2020-06-16 15:31:59.100  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.101  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.103  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.112  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.114  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.114  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719112
2020-06-16 15:31:59.114  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.115  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.118  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.131  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.131  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.131  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719131
2020-06-16 15:31:59.132  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.132  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.135  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.142  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.142  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.142  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719142
2020-06-16 15:31:59.143  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.143  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.162  INFO 6584 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-16 15:32:02.171  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.171  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.173  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.173  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.174  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.176  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:02.176  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.176  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:02.178  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:02.918  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.964  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.978  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.980  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:03.011  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:03.013  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:04.793  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:04.794  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:04.807  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:04.808  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:04.808  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:04.809  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:05.584  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:05.584  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:05.585  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:05.585  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:08.059  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Finished assignment for group at generation 274: {consumer-56y1nhk1-exception-group-1-72949b56-c603-4777-9c78-fa944af15f61=Assignment(partitions=[56y1nhk1-exception-topic-0]), consumer-56y1nhk1-exception-group-2-27dc7411-b57c-490e-82a2-972b807bcb48=Assignment(partitions=[56y1nhk1-exception-topic-1]), consumer-56y1nhk1-exception-group-5-2e331e40-4945-4245-9fd9-c1866754bfe7=Assignment(partitions=[56y1nhk1-exception-topic-4]), consumer-56y1nhk1-exception-group-4-fb8d6f70-e93b-4048-ae9c-66ad804aa5cf=Assignment(partitions=[56y1nhk1-exception-topic-3]), consumer-56y1nhk1-exception-group-3-24d7fa07-d7ee-4f0f-b01e-20ae12802d20=Assignment(partitions=[56y1nhk1-exception-topic-2])}
2020-06-16 15:32:08.507  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.509  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.510  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.511  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.511  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.515  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-4
2020-06-16 15:32:08.515  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-0
2020-06-16 15:32:08.516  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-2
2020-06-16 15:32:08.517  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-1
2020-06-16 15:32:08.518  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-3
2020-06-16 15:32:08.775  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-4 to the committed offset FetchPosition{offset=639, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-16 15:32:08.776  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-4]
2020-06-16 15:32:08.777  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-2 to the committed offset FetchPosition{offset=956, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-02.srvs.cloudkafka.com:9094 (id: 1 rack: null)], epoch=absent}}
2020-06-16 15:32:08.783  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-0 to the committed offset FetchPosition{offset=777, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-16 15:32:08.787  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-3 to the committed offset FetchPosition{offset=924, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-16 15:32:08.796  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-1 to the committed offset FetchPosition{offset=836, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-16 15:32:08.886  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-2]
2020-06-16 15:32:08.886  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-0]
2020-06-16 15:32:08.902  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-3]
2020-06-16 15:32:08.902  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-1]
2020-06-16 15:32:34.610  INFO 6584 --- [http-nio-8080-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-16 15:32:34.610  INFO 6584 --- [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-06-16 15:32:34.629  INFO 6584 --- [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet        : Completed initialization in 19 ms
2020-06-16 15:32:35.495  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.a.controller.TestController        : Test Method Called
2020-06-16 15:32:35.604  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-16 15:32:36.388  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-16 15:32:37.049  INFO 6584 --- [http-nio-8080-exec-3] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:27910}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:32:37.220  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-16 15:32:37.310  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-16 15:32:37.620  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-16 15:32:37.620  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>3123123</TradeDate>
</Trade>

2020-06-16 15:33:50.748  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.a.controller.TestController        : Test Method Called
2020-06-16 15:33:50.755  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-16 15:33:50.774  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-16 15:33:50.779  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-16 15:33:50.779  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>31/05/2020</TradeDate>
</Trade>

2020-06-16 15:34:22.787  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:34:22.790  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-16 15:34:23.174  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 377ms. Found 2 MongoDB repository interfaces.
2020-06-16 15:34:23.199  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:34:23.201  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-16 15:34:23.221  INFO 6172 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:34:23.222  INFO 6172 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:34:23.223  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 11ms. Found 0 Redis repository interfaces.
2020-06-16 15:34:23.496  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=931861825, epoch=174): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:23.629  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1882914864, epoch=171): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:25.991  INFO 6172 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-16 15:34:26.071  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:34:26.234  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:34:26.248  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:34:27.560  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:18761}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-16 15:34:27.563  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:18876}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-16 15:34:27.566  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:25355}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.641  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=72275300, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000008, setVersion=2, lastWriteDate=Tue Jun 16 15:34:22 IST 2020, lastUpdateTimeNanos=59277730651600}
2020-06-16 15:34:27.643  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=78887000, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:34:22 IST 2020, lastUpdateTimeNanos=59277734016800}
2020-06-16 15:34:27.647  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000008 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.647  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=85479800, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:34:22 IST 2020, lastUpdateTimeNanos=59277737798400}
2020-06-16 15:34:27.648  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.649  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.768  INFO 6172 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-16 15:34:29.352  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.683  INFO 6172 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-16 15:34:29.798  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.799  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.799  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869795
2020-06-16 15:34:29.806  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.810  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.819  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.827  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.828  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.828  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869827
2020-06-16 15:34:29.829  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.829  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.831  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.858  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.882  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.882  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869858
2020-06-16 15:34:29.883  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.883  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.887  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.897  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.897  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.897  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869897
2020-06-16 15:34:29.901  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.901  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.938  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.951  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.951  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.952  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869951
2020-06-16 15:34:29.952  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.952  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:30.072  INFO 6172 --- [main] c.c.stg.acknackgen.ConvertServiceTest    : Executing convertObjectTest Junit test
2020-06-16 15:34:30.416  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-16 15:34:30.471  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-16 15:34:30.584  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-16 15:34:30.584  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Equities</SecurityDescription>
    <Error>
        <ErrorDateTime>12/11/2011</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>11/11/2011</TradeDate>
</Trade>

2020-06-16 15:34:30.810  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.810  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.810  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.811  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.835  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.835  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.838  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.841  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.842  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.845  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.865  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.878  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.888  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.892  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.895  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.925  INFO 6172 --- [SpringContextShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-16 15:34:44.215  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Node 1 was unable to process the fetch request with (sessionId=1080173891, epoch=187): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:50.013  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=1343281180, epoch=190): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:50.203  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=1495037478, epoch=190): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:35:39.582  INFO 6584 --- [http-nio-8080-exec-8] c.c.s.a.controller.TestController        : Test Method Called
2020-06-16 15:35:39.722 ERROR 6584 --- [http-nio-8080-exec-8] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception

com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field "treId" (class com.citi.stg.acknackgen.model.trade.Trade), not marked as ignorable (5 known properties: "error", "tradeDate", "cashSecurity", "firm", "tradeId"])
 at [Source: (String)"{
    "treId": "HNC2347",
    "firm": "SLI",
    "error": {
        "errordt": "22/1/1999",
        "description": "Error"
    },
    "cashSecurity": {
        "securityType": "CP",
        "securityIdentifier": "XXX4567"
    },
    "tradeDate": "31/05/2020"
}"; line: 2, column: 15] (through reference chain: com.citi.stg.acknackgen.model.trade.Trade["treId"])
	at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:61) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnknownProperty(DeserializationContext.java:855) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1206) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1592) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1570) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:299) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:156) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4482) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3434) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3402) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.citi.stg.acknackgen.controller.TestController.test(TestController.java:32) ~[classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_241]
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_241]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_241]
	at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_241]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:879) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_241]
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at java.lang.Thread.run(Unknown Source) [na:1.8.0_241]

2020-06-16 15:36:31.059  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1962764461, epoch=169): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:36:31.696  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1912974101, epoch=166): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:37:12.160  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Node 1 was unable to process the fetch request with (sessionId=1005821771, epoch=183): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:37:36.586  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=2013683496, epoch=191): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:37:37.113  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=730398714, epoch=194): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:38:39.828  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=618284726, epoch=170): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:38:40.147  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1578431291, epoch=166): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:38:43.750  INFO 6584 --- [RMI TCP Connection(5)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-16 15:38:44.048  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-0
2020-06-16 15:38:44.048  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-1
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-4
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-4]
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-5-2e331e40-4945-4245-9fd9-c1866754bfe7 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.048  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-2
2020-06-16 15:38:44.050  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-2]
2020-06-16 15:38:44.050  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-3-24d7fa07-d7ee-4f0f-b01e-20ae12802d20 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-1]
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-2-27dc7411-b57c-490e-82a2-972b807bcb48 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-0]
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-1-72949b56-c603-4777-9c78-fa944af15f61 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-3
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-3]
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-4-fb8d6f70-e93b-4048-ae9c-66ad804aa5cf sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.054  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.054  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.299  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.300  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.305  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.307  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.354  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.480  INFO 6584 --- [RMI TCP Connection(5)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-16 15:38:44.552  INFO 6584 --- [RMI TCP Connection(5)-127.0.0.1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:27910}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 because the pool has been closed.
