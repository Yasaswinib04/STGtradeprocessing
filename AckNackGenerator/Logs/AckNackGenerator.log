2020-06-16 15:31:53.934  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:31:53.944  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-16 15:31:54.180  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 224ms. Found 2 MongoDB repository interfaces.
2020-06-16 15:31:54.204  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:31:54.207  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-16 15:31:54.231  INFO 6584 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:31:54.232  INFO 6584 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:31:54.232  INFO 6584 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 14ms. Found 0 Redis repository interfaces.
2020-06-16 15:31:54.956  INFO 6584 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-16 15:31:54.966  INFO 6584 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-16 15:31:54.966  INFO 6584 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-16 15:31:55.050  INFO 6584 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-16 15:31:55.050  INFO 6584 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 2313 ms
2020-06-16 15:31:55.291  INFO 6584 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-16 15:31:55.387  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:31:55.422  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:31:55.423  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:31:56.576  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:27891}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.576  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:18878}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-16 15:31:56.576  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:18761}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-16 15:31:56.657  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77215000, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:31:50 IST 2020, lastUpdateTimeNanos=59126746175600}
2020-06-16 15:31:56.658  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77755600, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:31:50 IST 2020, lastUpdateTimeNanos=59126746175600}
2020-06-16 15:31:56.657  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77256900, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000008, setVersion=2, lastWriteDate=Tue Jun 16 15:31:50 IST 2020, lastUpdateTimeNanos=59126746175500}
2020-06-16 15:31:56.659  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000008 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.659  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.660  INFO 6584 --- [cluster-ClusterId{value='5ee898938753b27a1bad597b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:31:56.725  INFO 6584 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-16 15:31:57.560  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:58.956  INFO 6584 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-16 15:31:59.047  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.048  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.048  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719043
2020-06-16 15:31:59.053  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.056  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.090  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.099  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.100  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.100  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719099
2020-06-16 15:31:59.100  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.101  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.103  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.112  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.114  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.114  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719112
2020-06-16 15:31:59.114  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.115  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.118  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.131  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.131  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.131  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719131
2020-06-16 15:31:59.132  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.132  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.135  INFO 6584 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:31:59.142  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:31:59.142  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:31:59.142  INFO 6584 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301719142
2020-06-16 15:31:59.143  INFO 6584 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:31:59.143  INFO 6584 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:31:59.162  INFO 6584 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-16 15:32:02.171  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.171  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.173  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.173  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.174  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.176  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:02.176  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.176  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:02.178  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:02.918  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.964  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-16 15:32:02.978  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:02.980  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:03.011  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-16 15:32:03.013  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:04.793  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:04.794  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:04.807  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:04.808  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:04.808  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:04.809  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:05.584  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:05.584  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-16 15:32:05.585  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:05.585  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-16 15:32:08.059  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Finished assignment for group at generation 274: {consumer-56y1nhk1-exception-group-1-72949b56-c603-4777-9c78-fa944af15f61=Assignment(partitions=[56y1nhk1-exception-topic-0]), consumer-56y1nhk1-exception-group-2-27dc7411-b57c-490e-82a2-972b807bcb48=Assignment(partitions=[56y1nhk1-exception-topic-1]), consumer-56y1nhk1-exception-group-5-2e331e40-4945-4245-9fd9-c1866754bfe7=Assignment(partitions=[56y1nhk1-exception-topic-4]), consumer-56y1nhk1-exception-group-4-fb8d6f70-e93b-4048-ae9c-66ad804aa5cf=Assignment(partitions=[56y1nhk1-exception-topic-3]), consumer-56y1nhk1-exception-group-3-24d7fa07-d7ee-4f0f-b01e-20ae12802d20=Assignment(partitions=[56y1nhk1-exception-topic-2])}
2020-06-16 15:32:08.507  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.509  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.510  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.511  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.511  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Successfully joined group with generation 274
2020-06-16 15:32:08.515  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-4
2020-06-16 15:32:08.515  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-0
2020-06-16 15:32:08.516  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-2
2020-06-16 15:32:08.517  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-1
2020-06-16 15:32:08.518  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-3
2020-06-16 15:32:08.775  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-4 to the committed offset FetchPosition{offset=639, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-16 15:32:08.776  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-4]
2020-06-16 15:32:08.777  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-2 to the committed offset FetchPosition{offset=956, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-02.srvs.cloudkafka.com:9094 (id: 1 rack: null)], epoch=absent}}
2020-06-16 15:32:08.783  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-0 to the committed offset FetchPosition{offset=777, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-16 15:32:08.787  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-3 to the committed offset FetchPosition{offset=924, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-16 15:32:08.796  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-1 to the committed offset FetchPosition{offset=836, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-16 15:32:08.886  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-2]
2020-06-16 15:32:08.886  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-0]
2020-06-16 15:32:08.902  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-3]
2020-06-16 15:32:08.902  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-1]
2020-06-16 15:32:34.610  INFO 6584 --- [http-nio-8080-exec-3] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-16 15:32:34.610  INFO 6584 --- [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-06-16 15:32:34.629  INFO 6584 --- [http-nio-8080-exec-3] o.s.web.servlet.DispatcherServlet        : Completed initialization in 19 ms
2020-06-16 15:32:35.495  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.a.controller.TestController        : Test Method Called
2020-06-16 15:32:35.604  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-16 15:32:36.388  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-16 15:32:37.049  INFO 6584 --- [http-nio-8080-exec-3] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:27910}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:32:37.220  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-16 15:32:37.310  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-16 15:32:37.620  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-16 15:32:37.620  INFO 6584 --- [http-nio-8080-exec-3] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>3123123</TradeDate>
</Trade>

2020-06-16 15:33:50.748  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.a.controller.TestController        : Test Method Called
2020-06-16 15:33:50.755  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-16 15:33:50.774  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-16 15:33:50.779  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-16 15:33:50.779  INFO 6584 --- [http-nio-8080-exec-4] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>31/05/2020</TradeDate>
</Trade>

2020-06-16 15:34:22.787  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:34:22.790  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-16 15:34:23.174  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 377ms. Found 2 MongoDB repository interfaces.
2020-06-16 15:34:23.199  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-16 15:34:23.201  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-16 15:34:23.221  INFO 6172 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:34:23.222  INFO 6172 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-16 15:34:23.223  INFO 6172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 11ms. Found 0 Redis repository interfaces.
2020-06-16 15:34:23.496  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=931861825, epoch=174): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:23.629  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1882914864, epoch=171): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:25.991  INFO 6172 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-16 15:34:26.071  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:34:26.234  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:34:26.248  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-16 15:34:27.560  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:18761}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-16 15:34:27.563  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:18876}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-16 15:34:27.566  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:25355}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.641  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=72275300, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000008, setVersion=2, lastWriteDate=Tue Jun 16 15:34:22 IST 2020, lastUpdateTimeNanos=59277730651600}
2020-06-16 15:34:27.643  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=78887000, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:34:22 IST 2020, lastUpdateTimeNanos=59277734016800}
2020-06-16 15:34:27.647  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000008 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.647  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=85479800, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-01-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Tue Jun 16 15:34:22 IST 2020, lastUpdateTimeNanos=59277737798400}
2020-06-16 15:34:27.648  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.649  INFO 6172 --- [cluster-ClusterId{value='5ee89929c412ee02e6089d94', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-16 15:34:27.768  INFO 6172 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-16 15:34:29.352  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.683  INFO 6172 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-16 15:34:29.798  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.799  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.799  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869795
2020-06-16 15:34:29.806  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.810  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.819  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.827  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.828  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.828  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869827
2020-06-16 15:34:29.829  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.829  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.831  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.858  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.882  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.882  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869858
2020-06-16 15:34:29.883  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.883  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.887  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.897  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.897  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.897  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869897
2020-06-16 15:34:29.901  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.901  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:29.938  INFO 6172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-16 15:34:29.951  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-16 15:34:29.951  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-16 15:34:29.952  INFO 6172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592301869951
2020-06-16 15:34:29.952  INFO 6172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-16 15:34:29.952  INFO 6172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-16 15:34:30.072  INFO 6172 --- [main] c.c.stg.acknackgen.ConvertServiceTest    : Executing convertObjectTest Junit test
2020-06-16 15:34:30.416  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-16 15:34:30.471  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-16 15:34:30.584  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-16 15:34:30.584  INFO 6172 --- [main] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Equities</SecurityDescription>
    <Error>
        <ErrorDateTime>12/11/2011</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>11/11/2011</TradeDate>
</Trade>

2020-06-16 15:34:30.810  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.810  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.810  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.811  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.835  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.835  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.838  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.841  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.842  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:34:30.845  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:34:30.865  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.878  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.888  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.892  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.895  INFO 6172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:34:30.925  INFO 6172 --- [SpringContextShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-16 15:34:44.215  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Node 1 was unable to process the fetch request with (sessionId=1080173891, epoch=187): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:50.013  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=1343281180, epoch=190): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:34:50.203  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=1495037478, epoch=190): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:35:39.582  INFO 6584 --- [http-nio-8080-exec-8] c.c.s.a.controller.TestController        : Test Method Called
2020-06-16 15:35:39.722 ERROR 6584 --- [http-nio-8080-exec-8] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception

com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field "treId" (class com.citi.stg.acknackgen.model.trade.Trade), not marked as ignorable (5 known properties: "error", "tradeDate", "cashSecurity", "firm", "tradeId"])
 at [Source: (String)"{
    "treId": "HNC2347",
    "firm": "SLI",
    "error": {
        "errordt": "22/1/1999",
        "description": "Error"
    },
    "cashSecurity": {
        "securityType": "CP",
        "securityIdentifier": "XXX4567"
    },
    "tradeDate": "31/05/2020"
}"; line: 2, column: 15] (through reference chain: com.citi.stg.acknackgen.model.trade.Trade["treId"])
	at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:61) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.DeserializationContext.handleUnknownProperty(DeserializationContext.java:855) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:1206) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1592) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1570) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:299) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:156) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4482) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3434) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3402) ~[jackson-databind-2.11.0.jar:2.11.0]
	at com.citi.stg.acknackgen.controller.TestController.test(TestController.java:32) ~[classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_241]
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_241]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[na:1.8.0_241]
	at java.lang.reflect.Method.invoke(Unknown Source) ~[na:1.8.0_241]
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:190) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:138) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:105) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:879) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:793) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1040) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:943) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:909) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:660) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:741) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.2.6.RELEASE.jar:5.2.6.RELEASE]
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202) ~[tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:541) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:139) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:74) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:343) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:373) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1590) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source) [na:1.8.0_241]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source) [na:1.8.0_241]
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-9.0.35.jar:9.0.35]
	at java.lang.Thread.run(Unknown Source) [na:1.8.0_241]

2020-06-16 15:36:31.059  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1962764461, epoch=169): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:36:31.696  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1912974101, epoch=166): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:37:12.160  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Node 1 was unable to process the fetch request with (sessionId=1005821771, epoch=183): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:37:36.586  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=2013683496, epoch=191): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:37:37.113  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=730398714, epoch=194): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:38:39.828  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=618284726, epoch=170): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:38:40.147  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1578431291, epoch=166): FETCH_SESSION_ID_NOT_FOUND.
2020-06-16 15:38:43.750  INFO 6584 --- [RMI TCP Connection(5)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-16 15:38:44.048  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-0
2020-06-16 15:38:44.048  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-1
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-4
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-4]
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-5-2e331e40-4945-4245-9fd9-c1866754bfe7 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.048  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-2
2020-06-16 15:38:44.050  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-2]
2020-06-16 15:38:44.050  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-3-24d7fa07-d7ee-4f0f-b01e-20ae12802d20 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-1]
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-2-27dc7411-b57c-490e-82a2-972b807bcb48 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.049  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-0]
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-1-72949b56-c603-4777-9c78-fa944af15f61 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.051  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-3
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-3]
2020-06-16 15:38:44.052  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-4-fb8d6f70-e93b-4048-ae9c-66ad804aa5cf sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-16 15:38:44.054  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-16 15:38:44.054  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-16 15:38:44.299  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.300  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.305  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.307  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.354  INFO 6584 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-16 15:38:44.480  INFO 6584 --- [RMI TCP Connection(5)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-16 15:38:44.552  INFO 6584 --- [RMI TCP Connection(5)-127.0.0.1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:27910}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 because the pool has been closed.
2020-06-17 17:33:50.424  INFO 11740 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 17:33:50.428  INFO 11740 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-17 17:33:50.507  INFO 11740 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 74ms. Found 2 MongoDB repository interfaces.
2020-06-17 17:33:50.524  INFO 11740 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 17:33:50.526  INFO 11740 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-17 17:33:50.543  INFO 11740 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 17:33:50.544  INFO 11740 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 17:33:50.544  INFO 11740 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 10ms. Found 0 Redis repository interfaces.
2020-06-17 17:33:51.164  INFO 11740 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-17 17:33:51.173  INFO 11740 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-17 17:33:51.174  INFO 11740 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-17 17:33:51.259  INFO 11740 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-17 17:33:51.259  INFO 11740 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1988 ms
2020-06-17 17:33:51.435  INFO 11740 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[localhost:27017], mode=SINGLE, requiredClusterType=UNKNOWN, serverSelectionTimeout='30000 ms'}
2020-06-17 17:33:52.059  INFO 11740 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-17 17:33:52.631  INFO 11740 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 17:33:52.713  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 17:33:52.714  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 17:33:52.714  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592395432712
2020-06-17 17:33:52.716  INFO 11740 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 17:33:52.719  INFO 11740 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 17:33:52.724  INFO 11740 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 17:33:52.734  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 17:33:52.734  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 17:33:52.735  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592395432734
2020-06-17 17:33:52.735  INFO 11740 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 17:33:52.735  INFO 11740 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 17:33:52.738  INFO 11740 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 17:33:52.747  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 17:33:52.747  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 17:33:52.747  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592395432747
2020-06-17 17:33:52.748  INFO 11740 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 17:33:52.748  INFO 11740 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 17:33:52.750  INFO 11740 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 17:33:52.757  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 17:33:52.757  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 17:33:52.758  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592395432757
2020-06-17 17:33:52.758  INFO 11740 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 17:33:52.758  INFO 11740 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 17:33:52.760  INFO 11740 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 17:33:52.766  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 17:33:52.766  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 17:33:52.766  INFO 11740 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592395432766
2020-06-17 17:33:52.767  INFO 11740 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 17:33:52.767  INFO 11740 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 17:33:52.784  INFO 11740 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-17 17:33:54.727  INFO 11740 --- [cluster-ClusterId{value='5eea06a79b99b26103fe52e2', description='null'}-localhost:27017] org.mongodb.driver.cluster               : Exception in monitor thread while connecting to server localhost:27017

com.mongodb.MongoSocketOpenException: Exception opening socket
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:70) ~[mongodb-driver-core-4.0.3.jar:na]
	at com.mongodb.internal.connection.InternalStreamConnection.open(InternalStreamConnection.java:127) ~[mongodb-driver-core-4.0.3.jar:na]
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:117) ~[mongodb-driver-core-4.0.3.jar:na]
	at java.lang.Thread.run(Unknown Source) [na:1.8.0_241]
Caused by: java.net.ConnectException: Connection refused: connect
	at java.net.DualStackPlainSocketImpl.waitForConnect(Native Method) ~[na:1.8.0_241]
	at java.net.DualStackPlainSocketImpl.socketConnect(Unknown Source) ~[na:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.doConnect(Unknown Source) ~[na:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connectToAddress(Unknown Source) ~[na:1.8.0_241]
	at java.net.AbstractPlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_241]
	at java.net.PlainSocketImpl.connect(Unknown Source) ~[na:1.8.0_241]
	at java.net.SocksSocketImpl.connect(Unknown Source) ~[na:1.8.0_241]
	at java.net.Socket.connect(Unknown Source) ~[na:1.8.0_241]
	at com.mongodb.internal.connection.SocketStreamHelper.initialize(SocketStreamHelper.java:63) ~[mongodb-driver-core-4.0.3.jar:na]
	at com.mongodb.internal.connection.SocketStream.initializeSocket(SocketStream.java:79) ~[mongodb-driver-core-4.0.3.jar:na]
	at com.mongodb.internal.connection.SocketStream.open(SocketStream.java:65) ~[mongodb-driver-core-4.0.3.jar:na]
	... 3 common frames omitted

2020-06-17 17:33:54.926  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:54.927  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:54.927  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:54.927  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:54.927  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:54.926  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:54.927  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:54.928  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:54.928  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:54.928  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:57.009  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:57.010  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:57.025  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:57.025  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:57.071  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:57.071  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:57.071  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:57.072  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:57.071  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:57.072  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:59.142  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:59.142  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:59.205  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:59.205  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:59.205  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:59.205  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:59.205  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:59.205  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:33:59.221  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:33:59.222  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:01.424  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:01.425  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:01.428  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:01.429  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:01.439  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:01.440  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:01.470  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:01.471  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:01.549  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:01.549  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:03.826  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:03.827  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:03.907  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:03.907  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:03.939  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:03.939  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:03.956  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:03.956  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:04.018  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:04.018  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:06.537  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:06.537  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:06.681  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:06.682  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:06.728  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:06.728  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:06.776  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:06.777  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:06.871  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:06.871  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:09.630  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:09.630  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:09.661  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:09.661  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:09.773  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:09.773  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:09.821  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:09.821  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:09.821  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:09.821  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:12.684  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:12.684  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:12.796  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:12.797  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:12.909  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:12.909  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:12.909  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:12.909  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:12.973  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:12.973  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:15.823  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:15.823  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:15.904  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:15.904  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:15.935  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:15.936  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:16.124  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:16.124  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:16.186  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:16.186  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:18.843  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:18.843  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:19.017  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:19.017  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:19.033  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:19.033  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:19.048  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:19.049  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:19.221  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:19.221  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:21.545  INFO 11740 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-17 17:34:21.730  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Connection to node -1 (localhost/127.0.0.1:9092) could not be established. Broker may not be available.
2020-06-17 17:34:21.730  WARN 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.NetworkClient   : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Bootstrap broker localhost:9092 (id: -1 rack: null) disconnected
2020-06-17 17:34:21.771  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 17:34:21.771  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 17:34:21.771  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 17:34:21.772  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 17:34:21.772  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 17:34:21.773  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 17:34:21.774  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 17:34:21.774  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 17:34:21.774  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 17:34:21.775  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 17:34:21.782  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 17:34:21.784  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 17:34:21.785  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 17:34:21.785  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 17:34:21.786  INFO 11740 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 17:34:21.813  INFO 11740 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-17 18:03:03.431  INFO 8580 --- [main] c.c.stg.acknackgen.ConvertServiceTest    : No active profile set, falling back to default profiles: default
2020-06-17 18:03:04.369  INFO 8580 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 18:03:04.372  INFO 8580 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-17 18:03:04.701  INFO 8580 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 322ms. Found 2 MongoDB repository interfaces.
2020-06-17 18:03:04.729  INFO 8580 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 18:03:04.732  INFO 8580 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-17 18:03:04.773  INFO 8580 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 18:03:04.774  INFO 8580 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 18:03:04.774  INFO 8580 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 16ms. Found 0 Redis repository interfaces.
2020-06-17 18:03:05.344  INFO 8580 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=44e35944-d6ba-313c-bd76-80eaf9e1ea58
2020-06-17 18:03:07.229  INFO 8580 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$cf857482] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-06-17 18:03:10.825  INFO 8580 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-17 18:03:11.147  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 18:03:11.222  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 18:03:11.225  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 18:03:13.498  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:33313}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:03:13.498  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:40205}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-17 18:03:13.500  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:52790}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-17 18:03:13.550  INFO 8580 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-17 18:03:13.589  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=87188300, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000009, setVersion=2, lastWriteDate=Wed Jun 17 18:03:07 IST 2020, lastUpdateTimeNanos=154605971739200}
2020-06-17 18:03:13.595  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=94113900, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 18:03:07 IST 2020, lastUpdateTimeNanos=154605979218400}
2020-06-17 18:03:13.595  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000009 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:03:13.596  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:03:13.596  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:03:13.597  INFO 8580 --- [cluster-ClusterId{value='5eea0d86be4dad5179beab39', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=93240300, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 18:03:07 IST 2020, lastUpdateTimeNanos=154605981738800}
2020-06-17 18:03:17.988  INFO 8580 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:03:18.655  INFO 8580 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-17 18:03:18.915  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:03:18.916  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:03:18.916  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397198909
2020-06-17 18:03:18.920  INFO 8580 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:03:18.923  INFO 8580 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:03:18.935  INFO 8580 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:03:18.947  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:03:18.947  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:03:18.947  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397198947
2020-06-17 18:03:18.952  INFO 8580 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:03:18.952  INFO 8580 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:03:18.969  INFO 8580 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:03:18.987  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:03:18.987  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:03:18.987  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397198987
2020-06-17 18:03:18.988  INFO 8580 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:03:18.988  INFO 8580 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:03:18.999  INFO 8580 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:03:19.008  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:03:19.009  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:03:19.009  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397199008
2020-06-17 18:03:19.010  INFO 8580 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:03:19.010  INFO 8580 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:03:19.028  INFO 8580 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:03:19.038  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:03:19.038  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:03:19.038  INFO 8580 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397199037
2020-06-17 18:03:19.039  INFO 8580 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:03:19.040  INFO 8580 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:03:19.071  INFO 8580 --- [main] c.c.stg.acknackgen.ConvertServiceTest    : Started ConvertServiceTest in 19.358 seconds (JVM running for 21.476)
2020-06-17 18:03:19.345  INFO 8580 --- [main] c.c.stg.acknackgen.ConvertServiceTest    : Executing convertObjectTest Junit test
2020-06-17 18:03:19.452  INFO 8580 --- [main] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 18:03:19.461  INFO 8580 --- [main] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 18:03:19.670  INFO 8580 --- [main] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 18:03:19.671  INFO 8580 --- [main] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Equities</SecurityDescription>
    <Error>
        <ErrorDateTime>12/11/2011</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>11/11/2011</TradeDate>
</Trade>

2020-06-17 18:03:20.015  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:03:20.015  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:03:20.016  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:03:20.015  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:03:20.023  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:03:20.024  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:03:20.023  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:03:20.026  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:03:20.027  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:03:20.027  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:03:20.033  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:03:20.037  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:03:20.039  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:03:20.040  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:03:20.040  INFO 8580 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:03:20.065  INFO 8580 --- [SpringContextShutdownHook] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-17 18:07:19.521  INFO 6400 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : No active profile set, falling back to default profiles: default
2020-06-17 18:07:20.196  INFO 6400 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 18:07:20.197  INFO 6400 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-17 18:07:20.281  INFO 6400 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 80ms. Found 2 MongoDB repository interfaces.
2020-06-17 18:07:20.297  INFO 6400 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 18:07:20.299  INFO 6400 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-17 18:07:20.321  INFO 6400 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 18:07:20.324  INFO 6400 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 18:07:20.325  INFO 6400 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 12ms. Found 0 Redis repository interfaces.
2020-06-17 18:07:20.606  INFO 6400 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=97bf9fba-39cf-3d22-8167-56db85a6fe42
2020-06-17 18:07:20.710  INFO 6400 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$e4517b09] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-06-17 18:07:20.912  INFO 6400 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-17 18:07:20.920  INFO 6400 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-17 18:07:20.920  INFO 6400 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-17 18:07:21.041  INFO 6400 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-17 18:07:21.041  INFO 6400 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1496 ms
2020-06-17 18:07:21.395  INFO 6400 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-17 18:07:21.526  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 18:07:21.569  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 18:07:21.570  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 18:07:22.354  INFO 6400 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-17 18:07:22.811  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:40803}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:07:22.811  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:40171}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-17 18:07:22.811  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:52790}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-17 18:07:22.890  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=75246000, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000009, setVersion=2, lastWriteDate=Wed Jun 17 18:07:15 IST 2020, lastUpdateTimeNanos=154855273056900}
2020-06-17 18:07:22.894  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000009 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:07:22.894  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:07:22.894  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:07:22.897  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=84904700, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 18:07:15 IST 2020, lastUpdateTimeNanos=154855281662500}
2020-06-17 18:07:22.897  INFO 6400 --- [cluster-ClusterId{value='5eea0e81dec25c6159335395', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=84832500, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 18:07:15 IST 2020, lastUpdateTimeNanos=154855281593700}
2020-06-17 18:07:23.906  INFO 6400 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:07:24.392  INFO 6400 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-17 18:07:24.452  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:07:24.452  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:07:24.453  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397444450
2020-06-17 18:07:24.457  INFO 6400 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:07:24.461  INFO 6400 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:07:24.467  INFO 6400 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:07:24.483  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:07:24.484  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:07:24.485  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397444483
2020-06-17 18:07:24.486  INFO 6400 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:07:24.486  INFO 6400 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:07:24.489  INFO 6400 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:07:24.501  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:07:24.501  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:07:24.501  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397444500
2020-06-17 18:07:24.502  INFO 6400 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:07:24.502  INFO 6400 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:07:24.506  INFO 6400 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:07:24.516  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:07:24.516  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:07:24.516  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397444515
2020-06-17 18:07:24.516  INFO 6400 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:07:24.516  INFO 6400 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:07:24.519  INFO 6400 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 18:07:24.555  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:07:24.556  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:07:24.556  INFO 6400 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397444555
2020-06-17 18:07:24.556  INFO 6400 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 18:07:24.557  INFO 6400 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 18:07:24.608  INFO 6400 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-17 18:07:24.626  INFO 6400 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : Started AckNackMicroservice in 7.309 seconds (JVM running for 8.06)
2020-06-17 18:07:27.532  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 18:07:27.534  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 18:07:27.537  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:27.554  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 18:07:27.555  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 18:07:27.556  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:27.557  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 18:07:27.561  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 18:07:27.562  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:27.616  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 18:07:27.617  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 18:07:27.618  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:27.671  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 18:07:27.671  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 18:07:27.673  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:29.976  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 18:07:29.977  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:30.021  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 18:07:30.021  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:30.339  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 18:07:30.339  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:30.432  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 18:07:30.432  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:30.696  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 18:07:30.696  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 18:07:33.238  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Finished assignment for group at generation 350: {consumer-56y1nhk1-exception-group-3-42d8a175-2575-4bc4-a8e2-6d3b6baac70e=Assignment(partitions=[56y1nhk1-exception-topic-2]), consumer-56y1nhk1-exception-group-2-8f3ba0b7-911f-48df-8577-212d428edef8=Assignment(partitions=[56y1nhk1-exception-topic-1]), consumer-56y1nhk1-exception-group-1-6691f1c9-ab36-4e61-8016-f504e5b68233=Assignment(partitions=[56y1nhk1-exception-topic-0]), consumer-56y1nhk1-exception-group-4-5ae881ee-7db9-4e4b-a323-0fbcde9faaae=Assignment(partitions=[56y1nhk1-exception-topic-3]), consumer-56y1nhk1-exception-group-5-7cd4728c-5965-44f9-b55f-0e1048c81c54=Assignment(partitions=[56y1nhk1-exception-topic-4])}
2020-06-17 18:07:33.554  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Successfully joined group with generation 350
2020-06-17 18:07:33.554  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Successfully joined group with generation 350
2020-06-17 18:07:33.556  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Successfully joined group with generation 350
2020-06-17 18:07:33.557  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Successfully joined group with generation 350
2020-06-17 18:07:33.563  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-3
2020-06-17 18:07:33.563  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-2
2020-06-17 18:07:33.563  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-1
2020-06-17 18:07:33.563  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Successfully joined group with generation 350
2020-06-17 18:07:33.563  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-4
2020-06-17 18:07:33.565  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-0
2020-06-17 18:07:33.827  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-2 to the committed offset FetchPosition{offset=957, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-02.srvs.cloudkafka.com:9094 (id: 1 rack: null)], epoch=absent}}
2020-06-17 18:07:33.827  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-3 to the committed offset FetchPosition{offset=924, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 18:07:33.828  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-2]
2020-06-17 18:07:33.829  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-1 to the committed offset FetchPosition{offset=858, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 18:07:33.832  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-0 to the committed offset FetchPosition{offset=789, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 18:07:33.832  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-4 to the committed offset FetchPosition{offset=640, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 18:07:33.928  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-3]
2020-06-17 18:07:33.944  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-4]
2020-06-17 18:07:33.944  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-1]
2020-06-17 18:07:33.944  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-0]
2020-06-17 18:07:57.042  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.kafka.consumer.Consumer          : #### -> Consuming Trade from exception topic
2020-06-17 18:07:57.042  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.ProducerController    : Call to convertService to generate ackNack
2020-06-17 18:07:57.042  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 18:07:57.674  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-17 18:07:58.371  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:39267}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 18:07:58.475  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-17 18:07:58.551  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 18:07:58.590  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 18:07:58.590  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Equities</SecurityDescription>
    <Error>
        <ErrorDateTime>11/11/2019</ErrorDateTime>
        <Description>DUPLICATE TRADE</Description>
    </Error>
    <TradeDate>11/11/2019</TradeDate>
</Trade>

2020-06-17 18:07:58.591  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.ProducerController    : Call Producer to produce ack/nack
2020-06-17 18:07:58.591  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.kafka.producer.Producer          : #### -> Producing message to topic ack-nack topic
2020-06-17 18:07:58.596  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-17 18:07:58.712  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 18:07:58.712  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 18:07:58.712  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592397478712
2020-06-17 18:08:01.246  INFO 6400 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 18:08:01.252  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.kafka.consumer.Consumer          : #### -> Consuming Trade from exception topic
2020-06-17 18:08:01.253  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.ProducerController    : Call to convertService to generate ackNack
2020-06-17 18:08:01.253  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 18:08:01.255  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-17 18:08:01.328  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-17 18:08:01.397  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 18:08:01.400  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 18:08:01.401  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>Johnson Data Company</ClientName>
    <TradeId>XLY2567</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime></ErrorDateTime>
        <Description></Description>
    </Error>
    <TradeDate>05/02/2020</TradeDate>
</Trade>

2020-06-17 18:08:01.401  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.ProducerController    : Call Producer to produce ack/nack
2020-06-17 18:08:01.401  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.kafka.producer.Producer          : #### -> Producing message to topic ack-nack topic
2020-06-17 18:08:01.401  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.kafka.consumer.Consumer          : #### -> Consuming Trade from exception topic
2020-06-17 18:08:01.402  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.ProducerController    : Call to convertService to generate ackNack
2020-06-17 18:08:01.402  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 18:08:01.403  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-17 18:08:01.477  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-17 18:08:01.548  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 18:08:01.553  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 18:08:01.553  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>Finance Analysis Company</ClientName>
    <TradeId>QPZ9061</TradeId>
    <SecurityDescription>Fixed Deposit</SecurityDescription>
    <Error>
        <ErrorDateTime>21/04/2020</ErrorDateTime>
        <Description>DUPLICATE TRADE</Description>
    </Error>
    <TradeDate>18/04/2020</TradeDate>
</Trade>

2020-06-17 18:08:01.553  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.controller.ProducerController    : Call Producer to produce ack/nack
2020-06-17 18:08:01.554  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] c.c.s.a.kafka.producer.Producer          : #### -> Producing message to topic ack-nack topic
2020-06-17 18:08:55.164  INFO 6400 --- [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-17 18:08:55.164  INFO 6400 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-06-17 18:08:55.173  INFO 6400 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2020-06-17 18:08:55.220  INFO 6400 --- [http-nio-8080-exec-2] c.c.s.a.controller.TestController        : Test Method Called
2020-06-17 18:08:55.226  INFO 6400 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 18:08:55.237  INFO 6400 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 18:08:55.243  INFO 6400 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 18:08:55.243  INFO 6400 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>31/05/2020</TradeDate>
</Trade>

2020-06-17 18:09:09.597  INFO 6400 --- [RMI TCP Connection(2)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-17 18:09:09.788  INFO 6400 --- [RMI TCP Connection(2)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2020-06-17 18:09:09.790  INFO 6400 --- [RMI TCP Connection(2)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-2
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-4
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-0
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-1
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-0]
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-4]
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-2]
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-1]
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-3
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-3-42d8a175-2575-4bc4-a8e2-6d3b6baac70e sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-5-7cd4728c-5965-44f9-b55f-0e1048c81c54 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-3]
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-2-8f3ba0b7-911f-48df-8577-212d428edef8 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 18:09:09.802  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-1-6691f1c9-ab36-4e61-8016-f504e5b68233 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 18:09:09.803  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-4-5ae881ee-7db9-4e4b-a323-0fbcde9faaae sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:09:09.804  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 18:09:10.058  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:09:10.061  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:09:10.064  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:09:10.118  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:09:10.175  INFO 6400 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 18:09:10.294  INFO 6400 --- [RMI TCP Connection(2)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-17 18:09:10.295  INFO 6400 --- [RMI TCP Connection(2)-127.0.0.1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2020-06-17 18:09:10.367  INFO 6400 --- [RMI TCP Connection(2)-127.0.0.1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:39267}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 because the pool has been closed.
2020-06-17 19:20:41.205  INFO 9172 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : No active profile set, falling back to default profiles: default
2020-06-17 19:20:41.715  INFO 9172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 19:20:41.716  INFO 9172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-17 19:20:41.777  INFO 9172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 57ms. Found 2 MongoDB repository interfaces.
2020-06-17 19:20:41.790  INFO 9172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 19:20:41.792  INFO 9172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-17 19:20:41.805  INFO 9172 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 19:20:41.806  INFO 9172 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 19:20:41.806  INFO 9172 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 7ms. Found 0 Redis repository interfaces.
2020-06-17 19:20:42.042  INFO 9172 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=97bf9fba-39cf-3d22-8167-56db85a6fe42
2020-06-17 19:20:42.150  INFO 9172 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$b5ba489f] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-06-17 19:20:42.332  INFO 9172 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-17 19:20:42.340  INFO 9172 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-17 19:20:42.340  INFO 9172 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-17 19:20:42.415  INFO 9172 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-17 19:20:42.416  INFO 9172 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1188 ms
2020-06-17 19:20:42.646  INFO 9172 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-17 19:20:42.721  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:20:42.747  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:20:42.748  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:20:43.328  INFO 9172 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-17 19:20:43.807  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:52642}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-17 19:20:43.807  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:42668}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-17 19:20:43.824  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:35942}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:20:43.875  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=65230500, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 19:20:41 IST 2020, lastUpdateTimeNanos=159256262275700}
2020-06-17 19:20:43.881  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=73656400, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 19:20:41 IST 2020, lastUpdateTimeNanos=159256270043000}
2020-06-17 19:20:43.897  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=73159400, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000009, setVersion=2, lastWriteDate=Wed Jun 17 19:20:41 IST 2020, lastUpdateTimeNanos=159256285301700}
2020-06-17 19:20:43.897  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000009 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:20:43.898  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:20:43.898  INFO 9172 --- [cluster-ClusterId{value='5eea1fb201462a5bc1fcce2b', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:20:44.299  INFO 9172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:20:44.975  INFO 9172 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-17 19:20:45.018  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:20:45.018  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:20:45.018  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592401845016
2020-06-17 19:20:45.020  INFO 9172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:20:45.022  INFO 9172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:20:45.026  INFO 9172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:20:45.035  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:20:45.036  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:20:45.036  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592401845035
2020-06-17 19:20:45.036  INFO 9172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:20:45.037  INFO 9172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:20:45.038  INFO 9172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:20:45.046  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:20:45.046  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:20:45.046  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592401845046
2020-06-17 19:20:45.047  INFO 9172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:20:45.047  INFO 9172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:20:45.049  INFO 9172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:20:45.056  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:20:45.056  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:20:45.056  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592401845056
2020-06-17 19:20:45.057  INFO 9172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:20:45.057  INFO 9172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:20:45.059  INFO 9172 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:20:45.065  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:20:45.065  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:20:45.065  INFO 9172 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592401845065
2020-06-17 19:20:45.066  INFO 9172 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:20:45.066  INFO 9172 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:20:45.082  INFO 9172 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-17 19:20:45.094  INFO 9172 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : Started AckNackMicroservice in 5.818 seconds (JVM running for 6.637)
2020-06-17 19:20:47.807  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:20:47.809  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:20:47.813  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:47.838  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:20:47.841  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:20:47.842  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:47.852  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:20:47.857  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:20:47.861  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:20:47.861  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:20:47.862  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:47.863  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:47.873  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:20:47.874  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:20:47.875  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:50.606  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:20:50.628  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:50.690  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:20:50.691  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:50.752  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:20:50.753  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:50.777  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:20:50.777  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:51.152  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:20:51.153  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:20:54.093  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Finished assignment for group at generation 352: {consumer-56y1nhk1-exception-group-2-2bf76d6e-3389-42d2-af10-88a5432cb46c=Assignment(partitions=[56y1nhk1-exception-topic-1]), consumer-56y1nhk1-exception-group-5-32d2a799-5fcb-40c8-9739-0543ec595a54=Assignment(partitions=[56y1nhk1-exception-topic-4]), consumer-56y1nhk1-exception-group-3-275ba85e-f945-4252-9a84-056b60509d27=Assignment(partitions=[56y1nhk1-exception-topic-2]), consumer-56y1nhk1-exception-group-4-1ff1886d-e36c-4a45-8c29-103ba266c894=Assignment(partitions=[56y1nhk1-exception-topic-3]), consumer-56y1nhk1-exception-group-1-9e242dd5-f1a4-4fd7-86dd-3fee902ea607=Assignment(partitions=[56y1nhk1-exception-topic-0])}
2020-06-17 19:20:54.404  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Successfully joined group with generation 352
2020-06-17 19:20:54.404  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Successfully joined group with generation 352
2020-06-17 19:20:54.404  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Successfully joined group with generation 352
2020-06-17 19:20:54.405  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Successfully joined group with generation 352
2020-06-17 19:20:54.405  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Successfully joined group with generation 352
2020-06-17 19:20:54.448  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-4
2020-06-17 19:20:54.448  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-1
2020-06-17 19:20:54.448  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-0
2020-06-17 19:20:54.448  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-2
2020-06-17 19:20:54.447  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-3
2020-06-17 19:20:55.050  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-1 to the committed offset FetchPosition{offset=861, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 19:20:55.050  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-3 to the committed offset FetchPosition{offset=924, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 19:20:55.051  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-0 to the committed offset FetchPosition{offset=789, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 19:20:55.052  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-3]
2020-06-17 19:20:55.052  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-1]
2020-06-17 19:20:55.054  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-2 to the committed offset FetchPosition{offset=957, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-02.srvs.cloudkafka.com:9094 (id: 1 rack: null)], epoch=absent}}
2020-06-17 19:20:55.054  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-4 to the committed offset FetchPosition{offset=640, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 19:20:55.163  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-0]
2020-06-17 19:20:55.163  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-2]
2020-06-17 19:20:55.163  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-4]
2020-06-17 19:21:01.878  INFO 9172 --- [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-17 19:21:01.880  INFO 9172 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-06-17 19:21:01.899  INFO 9172 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 18 ms
2020-06-17 19:21:01.974  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.a.controller.TestController        : Test Method Called
2020-06-17 19:21:01.988  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 19:21:01.988  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Getting Firm Description from cache thorugh cacheController
2020-06-17 19:21:03.071  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-17 19:21:03.896  INFO 9172 --- [http-nio-8080-exec-2] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:33313}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:21:04.015  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Getting Asset Description from cache thorugh cacheController
2020-06-17 19:21:04.017  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-17 19:21:04.094  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 19:21:04.142  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 19:21:04.142  INFO 9172 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>31/05/2020</TradeDate>
</Trade>

2020-06-17 19:21:34.738  INFO 9172 --- [RMI TCP Connection(3)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-17 19:21:34.997  INFO 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2020-06-17 19:21:34.999  INFO 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2020-06-17 19:21:35.005  WARN 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-nioEventLoop-4-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
 io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
 io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:21:35.006  WARN 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:21:35.008  WARN 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:21:35.009  WARN 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-3] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:21:35.010  WARN 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-4] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:21:35.022  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-0
2020-06-17 19:21:35.023  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-0]
2020-06-17 19:21:35.023  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-1-9e242dd5-f1a4-4fd7-86dd-3fee902ea607 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:21:35.025  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-1
2020-06-17 19:21:35.025  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-1]
2020-06-17 19:21:35.025  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-2-2bf76d6e-3389-42d2-af10-88a5432cb46c sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:21:35.025  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-2
2020-06-17 19:21:35.026  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-2]
2020-06-17 19:21:35.026  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-3-275ba85e-f945-4252-9a84-056b60509d27 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:21:35.026  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-3
2020-06-17 19:21:35.026  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-3]
2020-06-17 19:21:35.027  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-4-1ff1886d-e36c-4a45-8c29-103ba266c894 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:21:35.027  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-4
2020-06-17 19:21:35.027  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-4]
2020-06-17 19:21:35.027  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-5-32d2a799-5fcb-40c8-9739-0543ec595a54 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:21:35.039  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:21:35.039  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:21:35.039  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:21:35.039  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:21:35.039  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:21:35.040  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:21:35.040  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:21:35.040  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:21:35.040  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:21:35.040  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:21:35.284  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:21:35.298  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:21:35.302  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:21:35.302  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:21:35.311  INFO 9172 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:21:35.439  INFO 9172 --- [RMI TCP Connection(3)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-17 19:21:35.516  INFO 9172 --- [RMI TCP Connection(3)-127.0.0.1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:33313}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 because the pool has been closed.
2020-06-17 19:24:41.202  INFO 5628 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : No active profile set, falling back to default profiles: default
2020-06-17 19:24:41.788  INFO 5628 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 19:24:41.789  INFO 5628 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-17 19:24:41.854  INFO 5628 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 61ms. Found 2 MongoDB repository interfaces.
2020-06-17 19:24:41.871  INFO 5628 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 19:24:41.873  INFO 5628 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-17 19:24:41.889  INFO 5628 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 19:24:41.890  INFO 5628 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 19:24:41.890  INFO 5628 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 9ms. Found 0 Redis repository interfaces.
2020-06-17 19:24:42.113  INFO 5628 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=97bf9fba-39cf-3d22-8167-56db85a6fe42
2020-06-17 19:24:42.213  INFO 5628 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$5016c730] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-06-17 19:24:42.399  INFO 5628 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-17 19:24:42.407  INFO 5628 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-17 19:24:42.408  INFO 5628 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-17 19:24:42.493  INFO 5628 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-17 19:24:42.493  INFO 5628 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1271 ms
2020-06-17 19:24:42.719  INFO 5628 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-17 19:24:42.785  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:24:42.816  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:24:42.817  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:24:43.394  INFO 5628 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-17 19:24:43.846  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:40803}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:24:43.846  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:52642}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-17 19:24:43.846  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:40171}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-17 19:24:43.922  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=72125500, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 19:24:33 IST 2020, lastUpdateTimeNanos=159496308350400}
2020-06-17 19:24:43.922  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=71929100, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 19:24:33 IST 2020, lastUpdateTimeNanos=159496308350600}
2020-06-17 19:24:43.926  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=77703600, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000009, setVersion=2, lastWriteDate=Wed Jun 17 19:24:33 IST 2020, lastUpdateTimeNanos=159496313490000}
2020-06-17 19:24:43.926  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000009 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:24:43.926  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:24:43.926  INFO 5628 --- [cluster-ClusterId{value='5eea20a24919581f0247f2e9', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:24:44.415  INFO 5628 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:24:44.642  INFO 5628 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-17 19:24:44.692  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:24:44.692  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:24:44.692  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402084690
2020-06-17 19:24:44.696  INFO 5628 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:24:44.698  INFO 5628 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:24:44.703  INFO 5628 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:24:44.714  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:24:44.714  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:24:44.715  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402084714
2020-06-17 19:24:44.715  INFO 5628 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:24:44.716  INFO 5628 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:24:44.718  INFO 5628 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:24:44.746  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:24:44.746  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:24:44.746  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402084745
2020-06-17 19:24:44.746  INFO 5628 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:24:44.747  INFO 5628 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:24:44.750  INFO 5628 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:24:44.758  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:24:44.758  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:24:44.758  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402084758
2020-06-17 19:24:44.759  INFO 5628 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:24:44.759  INFO 5628 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:24:44.761  INFO 5628 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:24:44.768  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:24:44.768  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:24:44.768  INFO 5628 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402084768
2020-06-17 19:24:44.769  INFO 5628 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:24:44.769  INFO 5628 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:24:44.790  INFO 5628 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-17 19:24:44.801  INFO 5628 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : Started AckNackMicroservice in 5.614 seconds (JVM running for 6.439)
2020-06-17 19:24:47.557  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:24:47.557  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:24:47.557  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:24:47.559  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:24:47.559  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:24:47.559  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:24:47.561  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:24:47.563  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:24:47.563  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:47.563  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:24:47.564  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:24:47.564  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:47.565  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:47.565  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:47.565  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:50.216  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:24:50.242  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:50.246  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:24:50.246  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:50.323  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:24:50.323  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:50.516  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:24:50.516  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:50.518  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:24:50.518  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:24:53.532  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Finished assignment for group at generation 354: {consumer-56y1nhk1-exception-group-2-9b9f7fc3-4d2d-44b1-b676-9bb8767858a7=Assignment(partitions=[56y1nhk1-exception-topic-1]), consumer-56y1nhk1-exception-group-1-bda93848-5656-4b3c-8fe7-2c77dc8d90a5=Assignment(partitions=[56y1nhk1-exception-topic-0]), consumer-56y1nhk1-exception-group-4-2b35c7b7-3dcf-44a7-820b-3f642d791d60=Assignment(partitions=[56y1nhk1-exception-topic-3]), consumer-56y1nhk1-exception-group-3-88e713d5-3ce1-4916-925f-ca27fc612006=Assignment(partitions=[56y1nhk1-exception-topic-2]), consumer-56y1nhk1-exception-group-5-c9635331-1e4c-4ca7-8673-1e1b224b38f6=Assignment(partitions=[56y1nhk1-exception-topic-4])}
2020-06-17 19:24:53.857  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Successfully joined group with generation 354
2020-06-17 19:24:53.859  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Successfully joined group with generation 354
2020-06-17 19:24:53.859  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Successfully joined group with generation 354
2020-06-17 19:24:53.860  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Successfully joined group with generation 354
2020-06-17 19:24:53.859  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Successfully joined group with generation 354
2020-06-17 19:24:53.866  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-2
2020-06-17 19:24:53.866  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-0
2020-06-17 19:24:53.866  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-3
2020-06-17 19:24:53.866  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-1
2020-06-17 19:24:53.866  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-4
2020-06-17 19:24:54.124  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-2 to the committed offset FetchPosition{offset=957, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-02.srvs.cloudkafka.com:9094 (id: 1 rack: null)], epoch=absent}}
2020-06-17 19:24:54.124  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-4 to the committed offset FetchPosition{offset=640, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 19:24:54.124  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-1 to the committed offset FetchPosition{offset=861, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 19:24:54.125  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-3 to the committed offset FetchPosition{offset=924, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 19:24:54.126  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-4]
2020-06-17 19:24:54.141  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-0 to the committed offset FetchPosition{offset=789, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 19:24:54.231  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-3]
2020-06-17 19:24:54.231  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-1]
2020-06-17 19:24:54.231  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-2]
2020-06-17 19:24:54.247  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-0]
2020-06-17 19:24:59.055  INFO 5628 --- [http-nio-8080-exec-2] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-17 19:24:59.056  INFO 5628 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-06-17 19:24:59.065  INFO 5628 --- [http-nio-8080-exec-2] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2020-06-17 19:24:59.112  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.a.controller.TestController        : Test Method Called
2020-06-17 19:24:59.125  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 19:24:59.126  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade ObjectTrade [tradeId=HNC2347, firm=SLI, error=SourceError [errordt=22/1/1999, description=Error], cashSecurity=CashSecurity [securityType=CP, securityIdentifier=XXX4567], tradeDate=31/05/2020]
2020-06-17 19:24:59.126  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Getting Firm Description from cache thorugh cacheController
2020-06-17 19:24:59.944  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Getting Asset Description from cache thorugh cacheController
2020-06-17 19:24:59.947  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 19:25:00.193  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 19:25:00.193  INFO 5628 --- [http-nio-8080-exec-2] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>31/05/2020</TradeDate>
</Trade>

2020-06-17 19:27:03.089  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1682510035, epoch=166): FETCH_SESSION_ID_NOT_FOUND.
2020-06-17 19:27:03.738  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Node 0 was unable to process the fetch request with (sessionId=1663382962, epoch=165): FETCH_SESSION_ID_NOT_FOUND.
2020-06-17 19:27:05.859  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Node 1 was unable to process the fetch request with (sessionId=1668798813, epoch=172): FETCH_SESSION_ID_NOT_FOUND.
2020-06-17 19:27:07.986  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=49061541, epoch=168): FETCH_SESSION_ID_NOT_FOUND.
2020-06-17 19:27:08.021  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.kafka.clients.FetchSessionHandler    : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Node 2 was unable to process the fetch request with (sessionId=1924722391, epoch=170): FETCH_SESSION_ID_NOT_FOUND.
2020-06-17 19:27:38.139  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.kafka.consumer.Consumer          : #### -> Consuming Trade from exception topic
2020-06-17 19:27:38.139  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.ProducerController    : Call to convertService to generate ackNack
2020-06-17 19:27:38.139  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 19:27:38.139  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade ObjectTrade [tradeId=HNC2347, firm=SLI, error=SourceError [errordt=11/11/2019, description=DUPLICATE TRADE], cashSecurity=CashSecurity [securityType=EQ, securityIdentifier=XXX4586], tradeDate=11/11/2019]
2020-06-17 19:27:38.139  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Getting Firm Description from cache thorugh cacheController
2020-06-17 19:27:38.142  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Getting Asset Description from cache thorugh cacheController
2020-06-17 19:27:38.147  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-17 19:27:38.745  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:4, serverValue:40760}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:27:38.848  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 19:27:38.851  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 19:27:38.851  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Equities</SecurityDescription>
    <Error>
        <ErrorDateTime>11/11/2019</ErrorDateTime>
        <Description>DUPLICATE TRADE</Description>
    </Error>
    <TradeDate>11/11/2019</TradeDate>
</Trade>

2020-06-17 19:27:38.851  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.ProducerController    : Call Producer to produce ack/nack
2020-06-17 19:27:38.852  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.kafka.producer.Producer          : #### -> Producing message to topic ack-nack topic
2020-06-17 19:27:38.855  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.producer.ProducerConfig    : ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

2020-06-17 19:27:38.929  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:27:38.930  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:27:38.930  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402258929
2020-06-17 19:27:41.573  INFO 5628 --- [kafka-producer-network-thread | producer-1] org.apache.kafka.clients.Metadata        : [Producer clientId=producer-1] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:27:41.580  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.kafka.consumer.Consumer          : #### -> Consuming Trade from exception topic
2020-06-17 19:27:41.580  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.ProducerController    : Call to convertService to generate ackNack
2020-06-17 19:27:41.580  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 19:27:41.580  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade ObjectTrade [tradeId=XLY2567, firm=JDC, error=SourceError [errordt=, description=], cashSecurity=CashSecurity [securityType=CP, securityIdentifier=XXX4123], tradeDate=05/02/2020]
2020-06-17 19:27:41.580  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Getting Firm Description from cache thorugh cacheController
2020-06-17 19:27:41.582  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-17 19:27:41.654  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Getting Asset Description from cache thorugh cacheController
2020-06-17 19:27:41.656  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 19:27:41.659  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 19:27:41.659  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>Johnson Data Company</ClientName>
    <TradeId>XLY2567</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime></ErrorDateTime>
        <Description></Description>
    </Error>
    <TradeDate>05/02/2020</TradeDate>
</Trade>

2020-06-17 19:27:41.659  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.ProducerController    : Call Producer to produce ack/nack
2020-06-17 19:27:41.659  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.kafka.producer.Producer          : #### -> Producing message to topic ack-nack topic
2020-06-17 19:27:41.660  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.kafka.consumer.Consumer          : #### -> Consuming Trade from exception topic
2020-06-17 19:27:41.660  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.ProducerController    : Call to convertService to generate ackNack
2020-06-17 19:27:41.660  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object
2020-06-17 19:27:41.660  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade ObjectTrade [tradeId=QPZ9061, firm=FAC, error=SourceError [errordt=21/04/2020, description=DUPLICATE TRADE], cashSecurity=CashSecurity [securityType=FD, securityIdentifier=XXX2173], tradeDate=18/04/2020]
2020-06-17 19:27:41.660  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Getting Firm Description from cache thorugh cacheController
2020-06-17 19:27:41.661  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.CacheController       : Getting Firm from Database
2020-06-17 19:27:41.734  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Getting Asset Description from cache thorugh cacheController
2020-06-17 19:27:41.735  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.CacheController       : Getting Asset from Database
2020-06-17 19:27:41.805  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 19:27:41.807  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :
2020-06-17 19:27:41.808  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.acknackgen.service.ConvertService  : <?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>Finance Analysis Company</ClientName>
    <TradeId>QPZ9061</TradeId>
    <SecurityDescription>Fixed Deposit</SecurityDescription>
    <Error>
        <ErrorDateTime>21/04/2020</ErrorDateTime>
        <Description>DUPLICATE TRADE</Description>
    </Error>
    <TradeDate>18/04/2020</TradeDate>
</Trade>

2020-06-17 19:27:41.808  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.controller.ProducerController    : Call Producer to produce ack/nack
2020-06-17 19:27:41.808  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] c.c.s.a.kafka.producer.Producer          : #### -> Producing message to topic ack-nack topic
2020-06-17 19:28:15.698  INFO 5628 --- [RMI TCP Connection(4)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-17 19:28:15.898  INFO 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2020-06-17 19:28:15.901  INFO 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2020-06-17 19:28:15.906  WARN 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-nioEventLoop-4-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
 io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
 io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:28:15.907  WARN 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:28:15.908  WARN 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:28:15.917  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-1
2020-06-17 19:28:15.917  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-2
2020-06-17 19:28:15.917  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-0
2020-06-17 19:28:15.917  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-3
2020-06-17 19:28:15.917  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-4
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-3]
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-4]
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-0]
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-1]
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-2]
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-1-bda93848-5656-4b3c-8fe7-2c77dc8d90a5 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-2-9b9f7fc3-4d2d-44b1-b676-9bb8767858a7 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-3-88e713d5-3ce1-4916-925f-ca27fc612006 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-5-c9635331-1e4c-4ca7-8673-1e1b224b38f6 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:28:15.918  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-4-2b35c7b7-3dcf-44a7-820b-3f642d791d60 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:28:15.920  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:28:15.920  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:28:15.920  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:28:15.921  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:28:15.921  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:28:15.920  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:28:15.921  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:28:15.920  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:28:15.921  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:28:15.921  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:28:16.255  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:28:16.261  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:28:16.264  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:28:16.264  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:28:16.284  INFO 5628 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:28:16.410  INFO 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
2020-06-17 19:28:16.411  INFO 5628 --- [RMI TCP Connection(4)-127.0.0.1] o.a.k.clients.producer.KafkaProducer     : [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 30000 ms.
2020-06-17 19:28:16.485  INFO 5628 --- [RMI TCP Connection(4)-127.0.0.1] org.mongodb.driver.connection            : Closed connection [connectionId{localValue:4, serverValue:40760}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 because the pool has been closed.
2020-06-17 19:28:41.841  INFO 13296 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : No active profile set, falling back to default profiles: default
2020-06-17 19:28:42.415  INFO 13296 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 19:28:42.415  INFO 13296 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data MongoDB repositories in DEFAULT mode.
2020-06-17 19:28:42.482  INFO 13296 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 63ms. Found 2 MongoDB repository interfaces.
2020-06-17 19:28:42.496  INFO 13296 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Multiple Spring Data modules found, entering strict repository configuration mode!
2020-06-17 19:28:42.497  INFO 13296 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Bootstrapping Spring Data Redis repositories in DEFAULT mode.
2020-06-17 19:28:42.511  INFO 13296 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.AssetRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 19:28:42.512  INFO 13296 --- [main] .RepositoryConfigurationExtensionSupport : Spring Data Redis - Could not safely identify store assignment for repository candidate interface com.citi.stg.acknackgen.repository.FirmRepository. If you want this repository to be a Redis repository, consider annotating your entities with one of these annotations: org.springframework.data.redis.core.RedisHash (preferred), or consider extending one of the following types with your repository: org.springframework.data.keyvalue.repository.KeyValueRepository.
2020-06-17 19:28:42.512  INFO 13296 --- [main] .s.d.r.c.RepositoryConfigurationDelegate : Finished Spring Data repository scanning in 7ms. Found 0 Redis repository interfaces.
2020-06-17 19:28:42.740  INFO 13296 --- [main] o.s.cloud.context.scope.GenericScope     : BeanFactory id=97bf9fba-39cf-3d22-8167-56db85a6fe42
2020-06-17 19:28:42.847  INFO 13296 --- [main] trationDelegate$BeanPostProcessorChecker : Bean 'org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration' of type [org.springframework.cloud.autoconfigure.ConfigurationPropertiesRebinderAutoConfiguration$$EnhancerBySpringCGLIB$$46187350] is not eligible for getting processed by all BeanPostProcessors (for example: not eligible for auto-proxying)
2020-06-17 19:28:43.036  INFO 13296 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat initialized with port(s): 8080 (http)
2020-06-17 19:28:43.046  INFO 13296 --- [main] o.apache.catalina.core.StandardService   : Starting service [Tomcat]
2020-06-17 19:28:43.046  INFO 13296 --- [main] org.apache.catalina.core.StandardEngine  : Starting Servlet engine: [Apache Tomcat/9.0.35]
2020-06-17 19:28:43.122  INFO 13296 --- [main] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring embedded WebApplicationContext
2020-06-17 19:28:43.123  INFO 13296 --- [main] o.s.web.context.ContextLoader            : Root WebApplicationContext: initialization completed in 1267 ms
2020-06-17 19:28:43.364  INFO 13296 --- [main] org.mongodb.driver.cluster               : Cluster created with settings {hosts=[127.0.0.1:27017], srvHost=tradeprocessing-oasxz.mongodb.net, mode=MULTIPLE, requiredClusterType=REPLICA_SET, serverSelectionTimeout='30000 ms', requiredReplicaSetName='TradeProcessing-shard-0'}
2020-06-17 19:28:43.424  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-00-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:28:43.449  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-01-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:28:43.450  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-srv-tradeprocessing-oasxz.mongodb.net] org.mongodb.driver.cluster               : Adding discovered server tradeprocessing-shard-00-02-oasxz.mongodb.net:27017 to client view of cluster
2020-06-17 19:28:44.004  INFO 13296 --- [main] o.s.s.concurrent.ThreadPoolTaskExecutor  : Initializing ExecutorService 'applicationTaskExecutor'
2020-06-17 19:28:44.457  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:3, serverValue:52642}] to tradeprocessing-shard-00-01-oasxz.mongodb.net:27017
2020-06-17 19:28:44.457  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:2, serverValue:40760}] to tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:28:44.457  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.connection            : Opened connection [connectionId{localValue:1, serverValue:40171}] to tradeprocessing-shard-00-00-oasxz.mongodb.net:27017
2020-06-17 19:28:44.526  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-00-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=67575500, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 19:28:41 IST 2020, lastUpdateTimeNanos=159736913596200}
2020-06-17 19:28:44.527  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-01-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, type=REPLICA_SET_SECONDARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=70464500, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-01-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=null, setVersion=2, lastWriteDate=Wed Jun 17 19:28:41 IST 2020, lastUpdateTimeNanos=159736915934100}
2020-06-17 19:28:44.533  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Monitor thread successfully connected to server with description ServerDescription{address=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, type=REPLICA_SET_PRIMARY, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=8, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=76533900, setName='TradeProcessing-shard-0', canonicalAddress=tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, hosts=[tradeprocessing-shard-00-02-oasxz.mongodb.net:27017, tradeprocessing-shard-00-00-oasxz.mongodb.net:27017, tradeprocessing-shard-00-01-oasxz.mongodb.net:27017], passives=[], arbiters=[], primary='tradeprocessing-shard-00-02-oasxz.mongodb.net:27017', tagSet=TagSet{[Tag{name='nodeType', value='ELECTABLE'}, Tag{name='provider', value='AWS'}, Tag{name='region', value='AP_SOUTH_1'}]}, electionId=7fffffff0000000000000009, setVersion=2, lastWriteDate=Wed Jun 17 19:28:41 IST 2020, lastUpdateTimeNanos=159736922001700}
2020-06-17 19:28:44.534  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max election id to 7fffffff0000000000000009 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:28:44.534  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Setting max set version to 2 from replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:28:44.534  INFO 13296 --- [cluster-ClusterId{value='5eea2193d203210ce42ff946', description='null'}-tradeprocessing-shard-00-02-oasxz.mongodb.net:27017] org.mongodb.driver.cluster               : Discovered replica set primary tradeprocessing-shard-00-02-oasxz.mongodb.net:27017
2020-06-17 19:28:45.029  INFO 13296 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:28:45.254  INFO 13296 --- [main] o.a.k.c.s.authenticator.AbstractLogin    : Successfully logged in.
2020-06-17 19:28:45.339  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:28:45.340  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:28:45.340  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402325336
2020-06-17 19:28:45.345  INFO 13296 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:28:45.349  INFO 13296 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:28:45.355  INFO 13296 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:28:45.368  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:28:45.368  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:28:45.369  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402325368
2020-06-17 19:28:45.369  INFO 13296 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:28:45.370  INFO 13296 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:28:45.373  INFO 13296 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:28:45.392  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:28:45.393  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:28:45.393  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402325392
2020-06-17 19:28:45.394  INFO 13296 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:28:45.395  INFO 13296 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:28:45.398  INFO 13296 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:28:45.409  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:28:45.409  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:28:45.410  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402325409
2020-06-17 19:28:45.410  INFO 13296 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:28:45.411  INFO 13296 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:28:45.416  INFO 13296 --- [main] o.a.k.clients.consumer.ConsumerConfig    : ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [moped-01.srvs.cloudkafka.com:9094, moped-02.srvs.cloudkafka.com:9094, moped-03.srvs.cloudkafka.com:9094]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = 56y1nhk1-exception-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = [hidden]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = SCRAM-SHA-256
	security.protocol = SASL_SSL
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class com.citi.stg.acknackgen.kafka.consumer.TradeDeserializer

2020-06-17 19:28:45.425  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka version: 2.5.0
2020-06-17 19:28:45.425  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka commitId: 66563e712b0b9f84
2020-06-17 19:28:45.425  INFO 13296 --- [main] o.a.kafka.common.utils.AppInfoParser     : Kafka startTimeMs: 1592402325425
2020-06-17 19:28:45.426  INFO 13296 --- [main] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Subscribed to topic(s): 56y1nhk1-exception-topic
2020-06-17 19:28:45.426  INFO 13296 --- [main] o.s.s.c.ThreadPoolTaskScheduler          : Initializing ExecutorService
2020-06-17 19:28:45.453  INFO 13296 --- [main] o.s.b.w.embedded.tomcat.TomcatWebServer  : Tomcat started on port(s): 8080 (http) with context path ''
2020-06-17 19:28:45.470  INFO 13296 --- [main] c.c.stg.acknackgen.AckNackMicroservice   : Started AckNackMicroservice in 5.532 seconds (JVM running for 6.3)
2020-06-17 19:28:48.215  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:28:48.216  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:28:48.220  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:48.597  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:28:48.860  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:28:48.861  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:49.099  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:28:49.100  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:28:49.102  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:49.228  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:28:49.230  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:28:49.231  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:49.696  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] org.apache.kafka.clients.Metadata        : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Cluster ID: oKidZzIGS8CpolkrwCTN7A
2020-06-17 19:28:49.702  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Discovered group coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null)
2020-06-17 19:28:49.703  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:50.885  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:28:50.886  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:51.610  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:28:51.612  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:51.874  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:28:51.877  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:52.507  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:28:52.507  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:52.864  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Join group failed with org.apache.kafka.common.errors.MemberIdRequiredException: The group member needs to have a valid member id before actually entering a consumer group
2020-06-17 19:28:52.864  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] (Re-)joining group
2020-06-17 19:28:54.144  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Finished assignment for group at generation 356: {consumer-56y1nhk1-exception-group-5-330ce8fa-25bb-4f14-9393-49f3812ee50a=Assignment(partitions=[56y1nhk1-exception-topic-4]), consumer-56y1nhk1-exception-group-3-d824c944-92df-4493-96f4-e35013d5c1ac=Assignment(partitions=[56y1nhk1-exception-topic-2]), consumer-56y1nhk1-exception-group-1-01e42bb2-aa5f-4fae-bb9f-5bc0de19cbd7=Assignment(partitions=[56y1nhk1-exception-topic-0]), consumer-56y1nhk1-exception-group-2-53d78702-0a1c-46ff-abee-d678261a14a0=Assignment(partitions=[56y1nhk1-exception-topic-1]), consumer-56y1nhk1-exception-group-4-58243610-d759-46da-951e-dfdd9993184a=Assignment(partitions=[56y1nhk1-exception-topic-3])}
2020-06-17 19:28:54.464  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Successfully joined group with generation 356
2020-06-17 19:28:54.467  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Successfully joined group with generation 356
2020-06-17 19:28:54.467  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Successfully joined group with generation 356
2020-06-17 19:28:54.468  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Successfully joined group with generation 356
2020-06-17 19:28:54.475  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-0
2020-06-17 19:28:54.476  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-3
2020-06-17 19:28:54.476  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-1
2020-06-17 19:28:54.477  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-2
2020-06-17 19:28:54.478  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Successfully joined group with generation 356
2020-06-17 19:28:54.479  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Adding newly assigned partitions: 56y1nhk1-exception-topic-4
2020-06-17 19:28:54.734  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-0 to the committed offset FetchPosition{offset=792, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 19:28:54.735  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-0]
2020-06-17 19:28:54.736  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-3 to the committed offset FetchPosition{offset=924, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-03.srvs.cloudkafka.com:9094 (id: 2 rack: null)], epoch=absent}}
2020-06-17 19:28:54.739  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-2 to the committed offset FetchPosition{offset=957, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-02.srvs.cloudkafka.com:9094 (id: 1 rack: null)], epoch=absent}}
2020-06-17 19:28:54.744  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-1 to the committed offset FetchPosition{offset=861, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 19:28:54.746  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Setting offset for partition 56y1nhk1-exception-topic-4 to the committed offset FetchPosition{offset=640, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[moped-01.srvs.cloudkafka.com:9094 (id: 0 rack: null)], epoch=absent}}
2020-06-17 19:28:54.846  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-2]
2020-06-17 19:28:54.846  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-1]
2020-06-17 19:28:54.846  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-3]
2020-06-17 19:28:54.861  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions assigned: [56y1nhk1-exception-topic-4]
2020-06-17 19:29:02.536  INFO 13296 --- [http-nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Initializing Spring DispatcherServlet 'dispatcherServlet'
2020-06-17 19:29:02.536  INFO 13296 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Initializing Servlet 'dispatcherServlet'
2020-06-17 19:29:02.545  INFO 13296 --- [http-nio-8080-exec-1] o.s.web.servlet.DispatcherServlet        : Completed initialization in 9 ms
2020-06-17 19:29:02.580  INFO 13296 --- [http-nio-8080-exec-1] c.c.s.a.controller.TestController        : Test Method Called
2020-06-17 19:29:02.587  INFO 13296 --- [http-nio-8080-exec-1] c.c.s.acknackgen.service.ConvertService  : Setting the Fields of dest_Trade Object input trade :Trade [tradeId=HNC2347, firm=SLI, error=SourceError [errordt=22/1/1999, description=Error], cashSecurity=CashSecurity [securityType=CP, securityIdentifier=XXX4567], tradeDate=31/05/2020]
2020-06-17 19:29:02.587  INFO 13296 --- [http-nio-8080-exec-1] c.c.s.acknackgen.service.ConvertService  : Getting Firm Description from cache thorugh cacheController
2020-06-17 19:29:03.311  INFO 13296 --- [http-nio-8080-exec-1] c.c.s.acknackgen.service.ConvertService  : Getting Asset Description from cache thorugh cacheController
2020-06-17 19:29:03.314  INFO 13296 --- [http-nio-8080-exec-1] c.c.s.acknackgen.service.ConvertService  : Marshalling Ack/Nack to XML
2020-06-17 19:29:03.624  INFO 13296 --- [http-nio-8080-exec-1] c.c.s.acknackgen.service.ConvertService  : Generated Ack/Nack :<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<Trade>
    <ClientName>State Life Insurance</ClientName>
    <TradeId>HNC2347</TradeId>
    <SecurityDescription>Commercial Paper</SecurityDescription>
    <Error>
        <ErrorDateTime>22/1/1999</ErrorDateTime>
        <Description>Error</Description>
    </Error>
    <TradeDate>31/05/2020</TradeDate>
</Trade>

2020-06-17 19:29:18.251  INFO 13296 --- [RMI TCP Connection(4)-127.0.0.1] inMXBeanRegistrar$SpringApplicationAdmin : Application shutdown requested.
2020-06-17 19:29:18.443  INFO 13296 --- [RMI TCP Connection(4)-127.0.0.1] o.apache.catalina.core.StandardService   : Stopping service [Tomcat]
2020-06-17 19:29:18.445  INFO 13296 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.c.C.[Tomcat].[localhost].[/]       : Destroying Spring FrameworkServlet 'dispatcherServlet'
2020-06-17 19:29:18.449  WARN 13296 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-nioEventLoop-4-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll0(Native Method)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.poll(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl$SubSelector.access$400(Unknown Source)
 sun.nio.ch.WindowsSelectorImpl.doSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.lockAndDoSelect(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 sun.nio.ch.SelectorImpl.select(Unknown Source)
 io.netty.channel.nio.SelectedSelectionKeySetSelector.select(SelectedSelectionKeySetSelector.java:68)
 io.netty.channel.nio.NioEventLoop.select(NioEventLoop.java:803)
 io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:457)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:29:18.451  WARN 13296 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-1] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:29:18.452  WARN 13296 --- [RMI TCP Connection(4)-127.0.0.1] o.a.c.loader.WebappClassLoaderBase       : The web application [ROOT] appears to have started a thread named [lettuce-eventExecutorLoop-1-2] but has failed to stop it. This is very likely to create a memory leak. Stack trace of thread:
 sun.misc.Unsafe.park(Native Method)
 java.util.concurrent.locks.LockSupport.park(Unknown Source)
 java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(Unknown Source)
 java.util.concurrent.LinkedBlockingQueue.take(Unknown Source)
 io.netty.util.concurrent.SingleThreadEventExecutor.takeTask(SingleThreadEventExecutor.java:243)
 io.netty.util.concurrent.DefaultEventExecutor.run(DefaultEventExecutor.java:64)
 io.netty.util.concurrent.SingleThreadEventExecutor$4.run(SingleThreadEventExecutor.java:989)
 io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74)
 io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30)
 java.lang.Thread.run(Unknown Source)
2020-06-17 19:29:18.460  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-2
2020-06-17 19:29:18.460  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-3
2020-06-17 19:29:18.460  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-1
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-1]
2020-06-17 19:29:18.460  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-0
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-2]
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.ConsumerCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Revoke previously assigned partitions 56y1nhk1-exception-topic-4
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-0]
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-4]
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-3-d824c944-92df-4493-96f4-e35013d5c1ac sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-1-01e42bb2-aa5f-4fae-bb9f-5bc0de19cbd7 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-5-330ce8fa-25bb-4f14-9393-49f3812ee50a sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.k.l.KafkaMessageListenerContainer    : 56y1nhk1-exception-group: partitions revoked: [56y1nhk1-exception-topic-3]
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-2-53d78702-0a1c-46ff-abee-d678261a14a0 sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:29:18.461  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.c.c.internals.AbstractCoordinator  : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Member consumer-56y1nhk1-exception-group-4-58243610-d759-46da-951e-dfdd9993184a sending LeaveGroup request to coordinator moped-01.srvs.cloudkafka.com:9094 (id: 2147483647 rack: null) due to the consumer unsubscribed from all topics
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-2, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-4, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-5, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-3, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:29:18.464  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.a.k.clients.consumer.KafkaConsumer     : [Consumer clientId=consumer-56y1nhk1-exception-group-1, groupId=56y1nhk1-exception-group] Unsubscribed all topics or patterns and assigned partitions
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:29:18.464  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:29:18.463  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] o.s.s.c.ThreadPoolTaskScheduler          : Shutting down ExecutorService
2020-06-17 19:29:18.713  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:29:18.720  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-3-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:29:18.723  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-2-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:29:18.728  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-1-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:29:18.730  INFO 13296 --- [org.springframework.kafka.KafkaListenerEndpointContainer#0-4-C-1] essageListenerContainer$ListenerConsumer : 56y1nhk1-exception-group: Consumer stopped
2020-06-17 19:29:18.856  INFO 13296 --- [RMI TCP Connection(4)-127.0.0.1] o.s.s.concurrent.ThreadPoolTaskExecutor  : Shutting down ExecutorService 'applicationTaskExecutor'
